{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYr60kE6HnHMu8OpwHCUQl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdalazizOth/Tradtional_dict/blob/main/Kitab_Ayn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[KitabAyn_dict](https://raw.githubusercontent.com/OpenITI/RELEASE/v2023.1.8/data/0170KhalilFarahidi/0170KhalilFarahidi.Cayn/0170KhalilFarahidi.Cayn.Shamela0001682-ara1)**"
      ],
      "metadata": {
        "id": "pA9429CK1r1b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hzEQlD4ITk-a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab528b13-389f-4572-c2c4-2c8a977d37ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Done! 5798 roots extracted.\n",
            "ğŸ“„ Text file: KitabAyn.txt\n",
            "ğŸ“Š Excel file: KitabAyn.xlsx\n"
          ]
        }
      ],
      "source": [
        "import re                                # RegEx module for regular expressions\n",
        "import pandas as pd                      # Python library for data manipulation\n",
        "from openpyxl import load_workbook       # Python library to read/write Excel files\n",
        "from openpyxl.styles import Alignment\n",
        "\n",
        "# File paths\n",
        "input_file = \"/content/0170KhalilFarahidi.Cayn.Shamela0001682-ara1\"\n",
        "output_file_txt = \"KitabAyn.txt\"\n",
        "output_file_xlsx = \"KitabAyn.xlsx\"\n",
        "\n",
        "# Regex patterns\n",
        "page_pattern = re.compile(r\"PageV\\d{2}P\\d+\")        # Page number pattern like PageV01P66\n",
        "\n",
        "root_pattern = re.compile(\n",
        "   r\"^#\\s*(?!Ùˆ?(?:Ø£Ù‚ÙˆÙ„|Ù‚Ù„Øª|ÙŠÙ‚Ø§Ù„|Ù‚ÙŠÙ„|ØªÙ‚ÙˆÙ„|Ù‚ÙˆÙ„Ù‡|ÙŠÙ‚ÙˆÙ„|Ù‚Ø§Ù„|Ø§Ù„Ø§ÙˆÙ„|Ø¬Ø­Ø¯|Ø§Ù„Ù‚Ø·Ø¨|ÙŠØ±ÙˆÙŠ|Ø¨ÙˆØ²Ø¹|ÙŠØ±ÙˆÙ‰|Ø§Ù„Ø±Ù|Ø§Ù„ÙØ±|ÙˆØ±Ø¨|Ø¨Ø±Ø¨Ø±|ÙŠØ¨Ø±Ùƒ|Ø±Ø¤Ø¨Ø©|Ø£Ø±Ø§Ø¯|ÙŠØ¹Ù†ÙŠ|Ø¨Ø¹Ø¶Ù‡Ø§|Ø§Ù„Ø¶Ù‡Ø±|ÙˆØ¹Ù†Ø³|Ø§Ù„Ø£Ø²Ù„|Ù‡ÙˆÙ„ÙˆÙ„|Ø£Ø­Ø±Ø³|Ø¬Ù…Ø§Ø¯|ÙˆØ·Ø¹Ù…Ø©|Ø§Ù„Ø£Ø±ÙŠ|Ø¥ÙŠ|Ø£ÙŠ|ÙÙ‚Ø§Ù„|ÙÙŠÙ‚Ø§Ù„|ÙˆÙŠÙ‚Ø±Ø£|Ø¹Ù…Ø¯Ø§Ù†|Ø¹Ø±ÙŠÙ†Ø©|Ø±Ø¹ÙŠÙ†|ÙŠØ¹ÙØ±|ÙÙˆØ§Ø±Ø¹|Ø¨Ø§Ø±Ø¯|Ø¹ÙˆÙŠØ±|Ø§Ù„Ø³Ø·Ø­|ÙˆØ¹Ù„ÙŠ|Ù‚ÙˆØ§Ø±Ø¨|ÙˆÙ„Ø§Ø­Ù‚|ÙˆÙ‡ÙŠØª|Ù‡ÙŠØª: Ù…Ù†|ØªØ¹Ø§Ù„Ù‰|ÙˆØ§Ù„Ù„Ùƒ|ÙˆØ§Ù„ÙØ´|ÙˆØ§Ù„Ø±Ø³|Ø§Ù„Ø£Ù„Ø²|ÙˆØ§Ù„Ù†Ø³|ÙˆØ§Ù„Ø³Ù|Ø¥Ù†ÙŠ|Ø³Ø¨Ø§Ø·|Ù„Ø§|Ø§Ù„Ø³ÙŠ|ÙˆØ£Ø®Ø±Ø¬|ÙˆØ²Ø±Ù‡|ÙˆØ§Ù„Ø²Ø±|ÙˆØ§Ù„Ø²Ù|Ø¹Ù„ÙŠÙ‡Ø§|ÙˆØ§Ù„Ø¥Ù„|ÙˆØ§Ù„Ù…Ù†|ÙˆØ¹ÙŠÙˆÙ‚|Ø±Ø¹Ù…: Ø§Ø³Ù…|ÙÙ‚Ø·|Ø´ÙŠØ¦Ø§|ÙŠØ±ÙŠØ¯))\"\n",
        "   r\"([\\u0621-\\u064A]{2,5})\\s*[:ØŒ]\\s*(.*)\"\n",
        ")  # Root pattern (starting with #)\n",
        "\n",
        "\n",
        "# Initialize variables\n",
        "data = []\n",
        "page = None          # Current active page\n",
        "next_page = None     # Temporarily holds the next page marker (for future root)\n",
        "root = None\n",
        "text_lines = []\n",
        "\n",
        "# Process the file\n",
        "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for raw_line in f:\n",
        "        line = raw_line.rstrip()\n",
        "\n",
        "        if re.match(r\"^\\s*### \\|\", line):\n",
        "            continue\n",
        "\n",
        "        # Detect page marker (may appear within text)\n",
        "        if match := page_pattern.search(line):\n",
        "            next_page = match.group(0)           # store for the next root\n",
        "            line = page_pattern.sub(\"\", line)    # remove marker but keep text\n",
        "            line = line.strip()                  # trim spaces after removal\n",
        "\n",
        "        # Detect new root\n",
        "        if match := root_pattern.match(line):\n",
        "            # Save previous root (if one exists)\n",
        "            if root and text_lines:\n",
        "                text = \" \".join(text_lines).strip()\n",
        "                data.append((page, root, text))\n",
        "\n",
        "            # Assign correct page for this new root\n",
        "            # If a new page marker was found â†’ use it\n",
        "            # Otherwise â†’ keep using the previous page (same page for multiple roots)\n",
        "            if next_page is not None:\n",
        "                page = next_page\n",
        "                next_page = None\n",
        "\n",
        "            # Extract new root and first line of text\n",
        "            root = match.group(1).strip()\n",
        "            root = re.sub(r\"\\bms\\d{4}\\b\", \"\", root)\n",
        "\n",
        "\n",
        "\n",
        "            first_example_part = match.group(2).strip()\n",
        "            first_example_part = re.sub(r\"\\bms\\d{4}\\b|Â«\\d+Â»|\\|\\||\\.\\.\\.\", \"\", first_example_part)\n",
        "            text_lines = []\n",
        "            if first_example_part:\n",
        "                text_lines.append(first_example_part)\n",
        "\n",
        "        # Collect text lines under current root\n",
        "        elif root and line.strip():\n",
        "            cleaned = line.lstrip(\"#~ \").strip()\n",
        "            cleaned = re.sub(r\"\\bms\\d{4}\\b|Â«\\d+Â»|\\|\\||\\.\\.\\.\", \"\", cleaned)\n",
        "            if cleaned:\n",
        "                text_lines.append(cleaned)\n",
        "\n",
        "# Save the last root at end of file\n",
        "if root and text_lines:\n",
        "    text = \" \".join(text_lines).strip()\n",
        "    data.append((page, root, text))\n",
        "\n",
        "# 1ï¸âƒ£ Save text file\n",
        "with open(output_file_txt, \"w\", encoding=\"utf-8\") as out:\n",
        "    for page, root, text in data:\n",
        "        out.write(f\"Page: {page}\\nRoot: {root}\\nText: {text}\\n\\n\")\n",
        "\n",
        "# 2ï¸âƒ£ Save Excel file\n",
        "df = pd.DataFrame(data, columns=[\"Page\", \"Root\", \"Text\"])\n",
        "df.to_excel(output_file_xlsx, index=False, engine=\"openpyxl\")\n",
        "\n",
        "# 3ï¸âƒ£ Format Excel (RTL + wrap text)\n",
        "wb = load_workbook(output_file_xlsx)\n",
        "ws = wb.active\n",
        "\n",
        "ws.sheet_view.rightToLeft = True\n",
        "\n",
        "align = Alignment(wrap_text=True, horizontal=\"right\", vertical=\"top\")\n",
        "for row in ws.iter_rows():\n",
        "    for cell in row:\n",
        "        cell.alignment = align\n",
        "\n",
        "# Adjust column width (fixed reasonable size)\n",
        "ws.column_dimensions[\"A\"].width = 15   # Page\n",
        "ws.column_dimensions[\"B\"].width = 20   # Root\n",
        "ws.column_dimensions[\"C\"].width = 80   # Text\n",
        "\n",
        "wb.save(output_file_xlsx)\n",
        "\n",
        "print(f\"âœ… Done! {len(data)} roots extracted.\")  # to determine the number of items in data list\n",
        "print(f\"ğŸ“„ Text file: {output_file_txt}\")\n",
        "print(f\"ğŸ“Š Excel file: {output_file_xlsx}\")"
      ]
    }
  ]
}